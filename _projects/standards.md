---
layout: page
title: Technical Standards and Governance
description: 
importance: 1
category: social sciences
# related_publications: einstein1956investigations, einstein1950meaning
---


<hr>

I have a variety of interests in the development of technical standards by institutions, especially as they relate to evolving technologies where technological advancement substantially outpaces the development of governance patterns capable of mitigating risk and channeling these technologies toward socially-desirable ends.

A rather substantial area of interest within this much broader project relates to the implementation of information security standards like those promulgated by the National Institute of Standards in Technology (NIST). I am particularly fascinated by how NIST standards related to IT system risk management and authority-to-operate (ATO) correspond to relatively recent developments in how IT centers of excellence approach their work, namely, their increasing tendency to employ Agile work practices and cloud-based technologies.

I am also interested in legal standards related to electronic signatures in the United States, and how a rather permissive standard for establishing the legal sufficiency of digital signatures may create secondary effects for institutions - a phenomenon that I refer to as the "audit-trail problem." In this area of study, I make rather heavy use of Douglass North's conception of institutions, and Albert Hirschman's *Exit, Voice, Loyalty* to make sense of how the permissive standard creates a risk of distrust between firms and their employees. I also explore comparative electronic signature regimes and how these may provide insight into how to solve the "audit trail problem." I consider a set of hypothetical NIST standards that would promulgate a series of open technical standards related to electronic signature collection and validation, and consider approaches that allow entities to select signature standards that vary in their extensiveness based on costs, risks, and the entities particular needs. I also discuss the economic and social implications of an over-reliance on private firms like Adobe and DocuSign to implement audit trail systems and consider how open electronic signature standards could resolve potential equity concerns arising from this over-reliance.

I am interested in the opportunities presented by generative AI and have been thinking about governance models that seek to channel the use of AI by the government so as to minimize due process concerns. I am exploring how the use of AI in decision-making roles, or its use in close proximity to decision-making roles, may impact these concerns. I am also interested in existing frameworks for managing how government does its work, such as the idea of Inherently Governmental Functions, and I am considering the robustness of these frameworks to the issue of AI use by the federal government. I have taken to conceptualizing the underlying problem as "Schr√∂dinger's agency," by which I mean that AI sometimes acts like a tool, and sometimes acts like a human - though it is generally understood as not being able to explain itself or be held to account in the same way that a human can. This idea has been explored rather well by Madeleine Clare Elish in a 2019 article about the "Moral Crumple Zone." AI's quasi-autonomy that generative AI exhibits creates a problem with strict categorization, and invites a more creative approach in how we think about harms stemming from the use of AI by the federal government.




